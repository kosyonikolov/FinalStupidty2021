
\documentclass[fleqn,12pt]{article}

\usepackage[margin=15mm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[bulgarian]{babel}
\usepackage[unicode]{hyperref}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{enumitem, hyperref}
\usepackage{upgreek}
\usepackage{indentfirst}

\usepackage{amsmath}
\DeclareMathOperator{\cotg}{cotg}
\DeclareMathOperator{\LCS}{LCS}
\DeclareMathOperator{\longer}{longer}

\title{Модели на разпределени софтуерни архитектури. Среди и протоколи за разпределени приложения.}

\author{v0.1}
\date{25 юни 2021}

\begin{document}

\maketitle
\tableofcontents
\pagebreak

\section{Параметри на паралелната и разпределената обработка}

\subsection{Дадености}

\textbf{\textit{Разпределените (Дистрибутираните) системи}} са системи съставени от множество процеси разположени върху различни мрежови възли.
За краткост ще казваме възел когато имаме предвид мрежови възел.
Съставните компоненти комуникират помежду си чрез изпращане на съобщения посредством \textbf{IPC} методи.
\bigbreak
\textbf{\textit{Споделена памет}} между процеси наричаме памет, която е заделена върху точно един възел и може да бъде достъпена само от процесите върху него посредством шината на дънната платка.
\bigbreak
\textbf{\textit{Разпределена (Дистрибутирана) памет}} между процеси наричаме памет, която е задалена върху няколко възела и може да бъде достъпена чрез обмен на съобщения.
\bigbreak
\textbf{\textit{Паралелна обработка}} (\textit{Parallel computing}) наричаме обработка, при която една задача се разделя на подзадачи, които се изпълняват едновременно от няколко процесора.
Паметта между процесите при паралелната обработка може да е както споделена така и разпределена.
Задачите при паралелната обработка са tightly-coupled.
Чрез нея се спестява време.
\bigbreak
\textbf{\textit{Разпределена (Дистрибутирана) обработка}} (\textit{Distributed computing}) наричаме обработка, при която една задача се разделя на подзадачи, които се изпълняват върху различни възли.
Паметта между процесите при разпределена обработка може да е само разпределена.
Задачите при разпределената обработка са loosely-coupled.
Чрез разпределена обработка се постига стабилност.
\bigbreak
\textbf{\textit{Заб.}} - Една разпределена система може да включва както паралелна, така и разпределена обработка.

\subsection{Паралелни алгоритми и закон на Амдал}

\textbf{\textit{Сериен алгоритъм}} е алгоритъм, който може да изпълнява максимум една операция в даден момент.
Сложността може да се изчислява като функция на размера на входа.
\bigbreak

\textbf{\textit{Паралелен алгоритъм}} е алгоритъм, който може да изпълнява няколко операции едновременно.
Сложността може да се представи като функция на архитектурата и средата за паралелна обработка.

\bigbreak
Основните характерстики на паралелните алгоритми, които ги отличават от серийните са:
\begin{itemize}
    \item Брой процеси и логическата им организация
    \item Разпределение на данните и модел на техния обмен
    \item Точки на синхронизация на процесите
\end{itemize}
\bigbreak

За всеки алгоритъм е изпълнено, че не всяка негова част може да бъде паралелизирана.
Следователно не можем да ускоряваме до безкрайност.
\textbf{Законът на Амдал} гласи, че 
\begin{center}$S_{latency}(s) = \frac{1}{(1-p) + \frac{p}{s}}$, \end{center}
където:
\begin{itemize}
    \item $S_{latency}$ е теоретичното ускорение на изпълнението на цялата задача.
    \item $s$ е ускорението на секцията, която паралелизираме.
    \item $p$ е фракцията от времето на задачата заемано от секцията, която сме паралелизирали, при серийно изпълнение на алгоритъма.
\end{itemize}

\subsection{Метрики и методи за анализ на паралелните алгоритми}

\textbf{\textit{Степен на паралелизъм $p$}} в даден момент е максималният брой операции, които могат да се изпълняват паралелно при обработката на алгоритъма.
Т.е. процеси/нишки респективно брой ядра/възли.
\bigbreak
\textbf{\textit{Ускорение (acceleration)}} пресмятаме чрез $S_p = \frac{T_1}{T_p}$, където $T_1$ е времето за серийна обработка, а $T_p$ е времето за паралелна обработка при степен на паралелизъм $p$.
Поради наличие на комуникационни и синхронизационни закъснения $S_p \in (1, p)$.
\bigbreak
\textbf{\textit{Ефективност (efficiency)}} е частта от общото време за паралелна обработка, през която процесорите се използват ефективно.
Изразява се чрез $E_p = \frac{S_p}{p} = \frac{T_1}{pT_p}$, като $E_p \in (0, 1)$, където $S_p$ е ускорението, а $p$ е степента на паралелизъм.
\bigbreak
\textbf{\textit{Цена (cost)}} е времето отнето от процесорите за изпълнение на алгоритъма. Измерва се, чрез $C_p = pT_p$, където $T_p$ е времето за паралелна обработка при степен на паралелизъм $p$.
\bigbreak

\textbf{\textit{Грануларност}} е количеството работа за извършване на подзадачите, на които се разбива задачата на алгоритъм при паралелна обработка.
Тя може да се измерва във време използвайки следната формула $G = \frac{T_{comp}}{T_{comm}}$, където $T_{comp}$ е времето прекарано в изпълнение на подзадачите, а $T_{comm}$ е времето прекарано в комуникация между процесите.
Има няколко вида грануларност:
\begin{itemize}
    \item \textit{Фина}, където задачата се разбива на огромен брой малки подзадачи, които могат да се извършват паралелно.
    По този начин работата се разпределя равномерно между процесорите, което резултира в баланс на натоварването (\textit{load balancing}).
    Препоръчително е да се изолзва при $``$дисбалансирани$''$ данни за обработка, както и при наличие на бърза комуникация с малко \textit{overhead}, като при \textit{shared memory}.
    \item \textit{Едра}, където задачата се разбива на малък на брой големи подзадачи, които могат да се извършват паралелно.
    По този начин може да се стигне до дисбаланс между работата на процесорите.
    Препоръчителное да се използва при $``$балансирани$''$ данни за обработка, както и при наличие на бавна комуникация с много \textit{overhead}, като при \textit{message pasing}.
    \item \textit{Средна}, която е компромис между фината и едрата грануларност.
    Тя е най-често срещаната.
\end{itemize}
\bigbreak

Паралелните алгоритми се делят на асинхронни, локално синхронни и глобално синхронни.
\bigbreak

При разпределените системи топологията на разпределение на процесите влияе върху балансирането на натоварването между възлите. Тя може да бъде:
\begin{itemize}
    \item \textit{централизирана} - напр. звезда.
    \item \textit{йерархична} - напр. дървета
    \item \textit{разпределена} - напр. верига, решетка и хиперкуб.
\end{itemize}

\subsubsection{Аномалии при паралелните алгоритми}

\textbf{\textit{Суперлинейна аномалия}} наричаме случая когато $S_p > p$.
Тя може да се наблюдава при наличие на неоптимален сериен алгоритъм или при нисък капацитет на хардуер.
Пример е когато при серийна обработка данните заемат твърде много оперативна памет и се наложи използването на swap памет, докато при паралелна обработка данните заемат много по-малко памет и изчисленията се извършват изцяло с оперативната памет.

\textbf{\textit{Немонотонна аномалия}} наричаме случая когато $\exists p: S_p > S_{p+1}$.

\subsection{Модели на разпределените софтуерни архитектури и техните структури, организация, компоненти и приложение}

\subsection{Процедурни модели}
\subsection{Обектни модели}
\subsection{Потокови модели}
\subsection{Контекстни модели}
\subsection{Йерархични модели}
\subsection{Асинхронни модели}
\subsection{Интерактивни модели}

\section{Организация на разпределените приложения}

\subsection{Клиент-сървър и двуслойни архитектури}
\subsection{Трислойни архитектури}
\subsection{N-слойни архитектури}
\subsection{Peer-to-Peer архитектури}
\subsection{Сървъри за приложения и web-сървъри}
\subsection{Метасистеми и грид}
\subsection{Сервизно-ориентирани, моделно-ориентирани и аспектно-ориентирани архитектури}
\subsection{Софтуерни агенти}

\end{document}
