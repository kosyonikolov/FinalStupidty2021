
\documentclass[fleqn,12pt]{article}

\usepackage[margin=15mm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[bulgarian]{babel}
\usepackage[unicode]{hyperref}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{enumitem, hyperref}
\usepackage{upgreek}
\usepackage{indentfirst}
\usepackage{array}
\usepackage{listings}

\usepackage{amsmath}
\DeclareMathOperator{\cotg}{cotg}
\DeclareMathOperator{\LCS}{LCS}
\DeclareMathOperator{\longer}{longer}

\title{Структури от данни и алгоритми. Анализ на алгоритми. Абстрактни
типове от данни. Стек, опашка, списък, дърво. Сортиране.}

\author{v0.1}
\date{24 юни 2021}

\begin{document}

\maketitle

\tableofcontents

\section{Анализ на алгоритми}
\subsection{Въведение / необходимост}
TODO

\subsection{Асимптотична нотация на сложността}
\subsubsection{Дефиниция}
Нека $f, g : \mathbb{N} \rightarrow \mathbb{R}$. Казваме, че $f$ расте по-бавно от $g$ (или че $g$ мажорира $f$) и означаваме $f \prec g$, ако 
съществува $c \in \mathbb{R}$ и $n_0 \in \mathbb{N}$, за които е изпълнено $N > n_0 \Rightarrow f(N) < c.g(N)$.
Чрез $f \preceq g$ означаваме нестрогата форма на неравенството - $g$ расте поне толкова бързо, колкото $f$.

Нека $f : \mathbb{N} \rightarrow \mathbb{R}$. Дефинираме следните множества чрез релациите $\prec$ и $\preceq$:
\begin{itemize}
    \item $O(f) = \{g \hspace{2mm} | \hspace{2mm} g \preceq f\}$
    \item $o(f) = \{g \hspace{2mm} | \hspace{2mm} g \prec f\}$
    \item $\Omega(f) = \{g \hspace{2mm} | \hspace{2mm} f \preceq g\}$
    \item $\omega(f) = \{g \hspace{2mm} | \hspace{2mm} f \prec g\}$
    \item $\Theta(f) = \{g \hspace{2mm} | \hspace{2mm} f \preceq g \preceq f\}$
\end{itemize}

\subsubsection{Наредба на стандартните функции}
\noindent\[ C \prec \log \log N \prec \log N \prec \sqrt{N} \prec N \prec N^2 \prec N^3 \prec 2^N \prec 3^N \prec N! \prec N^N \]

\subsubsection{Свойства и примери}
Ако $f \preceq g$ и $h(n) = f(n) + g(n)$, то $h(n) \in \Theta(g)$.
Следвателно ни интересува само най-големия член на дадена формула, например
$N^2 + \log N + 5 \in O(N^2)$.

\subsection{Основни рекурентни формули}
\subsubsection{Дефиниция}
Нека с $T(N)$ обозначим времето за работа на алгоритъм при размер на входа $N$.
Ако можем да изразим $T(N)$ чрез формула, съдържаща $T$, то изразът наричаме \textbf{рекуретна формула}.
Такива изрази възникват често, когато алгоритми използват рекурсия.

Рекурентните формули можем да разглеждаме и като \textbf{рекурентни уравнения}, в които целта е да намерим израз за $T(N)$,
който не е рекурентна формула. Рекурентни уравнения могат да се решат по няколко начина: с индукция, с характеристично уравнение,
с мастър теорема и т.н.

Времето $T(N)$ можем да разглеждаме в най-лошия, средния и най-добрия случай (подредени по важност).
Освен време, по същия начин можем да разглеждаме и паметта, която алгоритъмът използва - нека я обозначим $M(N)$.
Очевидно $M(N) \preceq T(N)$.

\subsubsection{Примери}

\begin{center}
\begin{tabular}{|c|c|m{80mm}|}
    \hline
    Формула & Сложност & Примерен алгоритъм \\ 
    \hline
    $T(N) = T(N - 1) + N$ & $\Theta(N^2)$ & Наивна сортировка \\  
    \hline
    $T(N) = T\left(\dfrac{N}{2}\right) + 1$ & $\Theta(\log N)$ & Двоично търсене \\  
    \hline    
    $T(N) = T\left(\dfrac{N}{2}\right) + N$ & $\Theta(N)$ & Среден случай на търсене на медиана с \textbf{quick select} \\  
    \hline   
    $T(N) = 2T\left(\dfrac{N}{2}\right) + N$ & $\Theta(N \log N)$ & Бърза сортировка \\  
    \hline
    $T(N) = 2T\left(\dfrac{N}{2}\right) + 1$ & $\Theta(N)$ & Търсене на минимален елемент по схемата "разделяй и владей" \\  
    \hline     
\end{tabular}
\end{center}

\subsection{Примери за анализ на алгоритми}

\subsubsection{Двоично търсене}
Ще докажем, че сложността на двоичното търсене е $O(\log N)$.
Нека обозначим с $l_k$ и $r_k$ стойностите на променливите $left$ и $right$ на $k$-тата итерация на цикъла (нека първата итерация е $k = 0$).
Тогава размерът на масива, в който търсим, на всяка итерация е $N_k = r_k - l_k + 1$. За индекса на сравнение $m_k$ получваме
$m_k = \Big\lfloor\dfrac{l_k + r_k}{2}\Big\rfloor$ Интересува ни какво е $N_{k + 1}$, като имаме два случая:
\begin{itemize}
    \item $l_{k+1} = l_k, r_{k+1} = m_k - 1$. Тогава $N_{k+1} = \Big\lfloor\dfrac{l_k + r_k}{2}\Big\rfloor - 1 - l_k + 1 \leq \dfrac{l_k + r_k}{2} - l_k = \dfrac{N_k - 1}{2}$.
    Съответно $N_{k+1} \leq \Bigg\lfloor \dfrac{N_k}{2} \Bigg\rfloor$.
    \item $l_{k+1} = m_k + 1, r_{k+1} = r_k \Rightarrow N_{k+1} = r_k - \Big\lfloor\dfrac{l_k + r_k}{2}\Big\rfloor - 1 + 1 < \dfrac{r_k - l_k}{2} + 1 = \dfrac{N_k - 1}{2} + 1$. 
    $\dfrac{N_k - 1}{2} + 1 = \dfrac{N_k + 1}{2} = \Bigg\lceil \dfrac{N_k}{2} \Bigg\rceil$.
    Съответно получваме $N_{k+1} < \Bigg\lceil \dfrac{N_k}{2} \Bigg\rceil \Leftrightarrow N_{k+1} \leq \Bigg\lceil \dfrac{N_k}{2} \Bigg\rceil - 1 \Leftrightarrow $
    $N_{k+1} \leq \Bigg\lfloor \dfrac{N_k}{2} \Bigg\rfloor$
\end{itemize}

И двата случая получихме $N_{k+1} \leq \Bigg\lfloor \dfrac{N_k}{2} \Bigg\rfloor$.
Можем да приложим неравенството няколко пъти, както и да почнем от $N_0 = N$. 
Тогава получваме $N_k \leq \Bigg\lfloor \dfrac{N}{2^k} \Bigg\rfloor$. Алгоритъмът спира при $N_k < 1$,
следователно може да има най-много $\log_2 N$ стъпки $\Rightarrow O(\log N)$.

Алтернативно, можем да съставим рекурентна формула за времето в най-лошия случай - $T(n) = T\left(\frac{N}{2}\right) + 1$.
Вече споменахме, че за тази формула $T(n) \in \theta(\log N)$. 

Ако искаме да докажем и коректността на алгоритъма, то трябва да намерим и докажем инвариантата на цикъла.
В този случай това е следното твърдение: \textit{Елементът със стойност $target$ \textbf{не} се намира в подмасивите с индекси $0 \dots l_k - 1$ и $r_k + 1 \dots size - 1$}.
Доказването на инвариантите на цикъл обаче е извън обхвата на темата, така че ще го пропуснем.

\begin{lstlisting}[language=C++, caption=Двоично търсене]
int binary_search(const int * arr, const int size, const int target)
{
    int left = 0;
    int right = size - 1;

    while (left <= right)
    {
        const int m = (left + right) / 2;
        if (arr[m] == target) return m;
        if (arr[m] < target) left = m + 1;
        else right = m - 1;
    }

    return -1;
}
\end{lstlisting}
    

\section{Абстрактни типове от данни}
\subsection{Дефиниция и идея}
Често при програмирането използваме отделни компоненти наготово, без да ни интересува как точно си вършат работата.
Казваме, че такива компоненти са \textbf{абстракции}. Абстракциите улесняват писането на софтуер, като не ни карат 
да мислим за ненужни детайли.

Абстрактен тип данни е тип данни, който единствено дефинира какви операции поддържа и какъв \textbf{underlying} тип данни ползва.

\subsection{Интерфейс и реализация}
Поддържаните операции от някой абстрактен тип се наричат негов \textbf{интерфейс}. Интерфейсът е това, което клиентския код 
вижда и ползва. \textbf{Реализацията} е конкретен начин, по който е написан даден интерфейс - и съответно, абстрактен тип.
Тя остава скрита от клиентския код. За един интерфейс може да има много реализации.

\section{Свързани списъци}
\subsection{Дефиниция и структура}
Свързаните списъци се състоят от \textbf{възли}. Всеки възел съдържа стойност от \textbf{underlying} тип, както 
и указатели към предходен и/или следващ възел. В зависимост от това дали всеки възел съдържа един или два указателя,
списъкът се нарича \textbf{едносвързан} или \textbf{двусвързан}. Самият списък съдържа указател към първия възел, 
а при двусвързаните - понякога и към последния.

\subsection{Обработка на списъци}
Свързаните списъци поддържат операциите \textbf{добавяне} и \textbf{изтриване} на възли.
Понеже можем да променя указателите във всеки възел, можем ефикасно да режем и залепяме части от свързани списъци. 

\section{Структура от данни стек}
\subsection{Дефиниция и структура}
Стекът се оприличава на купчина обекти, защото поддържа следните операции:
\begin{itemize}
    \item Добавяне на елемент най-отгоре
    \item Премахване на най-горен елемент
    \item Проверяване на стойността на най-горния елемент
\end{itemize}

По-тази причина се казва, че стекът е \textbf{Last In, First Out (LIFO)} структура.

\subsection{Реализация}
Има няколко начина стек да се реализира:
\begin{itemize}
    \item Чрез статичен масив. При тази реализация стекът има краен размер. Пази се единствено индексът на най-горния елемент. 
    \item Чрез свързан списък. Най-горният елемент е последния възел на списъка.
    \item Чрез динамичен масив - ако текущият размер не стига, се алокира нов, по-голям, и елементите се копират там.
\end{itemize}

\section{Структура от данни опашка}
\subsection{Дефиниция и структура}
Опашката, както името й подсказва, поддържа следните операции:
\begin{itemize}
    \item Добавяне на елемент най-отзад
    \item Премахване на първия елемент (след това втория става първи)
    \item Проверяване на стойността на първия елемент
\end{itemize}

Опашката се нарича още \textbf{First In, First Out} структура.

\subsection{Реализация}
Възможните реализации са като при стека, с малки разлики. Ако се използват масиви, е необходимо да се съхранвят два индекса - на първи и на последен елемент.

\section{Дървета}
\subsection{Дефиниция и структура}
Дърветата са \textbf{ненасочени ациклични графи}, което означава че те са нелинейни структури от данни. Не е задължително да имат връх, който е обозначен за \textbf{корен}, но
напрактика повечето дървета се съхраняват като \textbf{коренови дървета}. Връзките в дървото могат да бъдат представени по няколко начина:
\begin{itemize}
    \item Чрез функция на бащите - всеки връх знае кой му е предшественика
    \item Чрез функция на наследниците - всеки връх знае кои са му преки наследници
    \item Имплицитно, чрез индекси (виж \ref{trees:heap})
\end{itemize}

\subsection{Понятия в дървета}
Върхове, които нямат наследници, се наричат \textbf{листа}. Броя наследници на даден връх наричаме негова \textbf{разклоненост}.
Разклоненост на дървото наричаме максималната допустима разклоненост на връх. Дължината на единствения път от корена до някой връх
наричаме \textbf{дълбочина} на върха. Максималната дълбочина на връх наричаме дълбочина на дървото.

\subsection{Типове дървета}
TODO

\subsubsection{Пирамида (heap)}
\label{trees:heap}
Пирамидите са почти перфектно балансирани двоични дървета - позволено е да липсват върхове единствено на последното (най-дълбоко) ниво.
Това ограничение позволява те да се съхраняват в масива без използване на указатели. Ако приемем, че масивите започват от 0, то тогава 
връх с индекс $i$ има родител на индекс $\Bigg\lfloor \dfrac{i - 1}{2} \Bigg\rfloor$ и ляво и дясно дете на индекси $2i + 1$, $2i + 2$.

Пирамидите поставят и друго ограничение - слаба наредба между родител и деца. По-конкретно, родителят трябва да е по-голям или по-малък
от децата, но не се казва кое дете трябва да е по-голямо. Това означава, че пирамидите ефикасно поддържат добавяне и премахване на елементи - за $O(\log N)$,
както и намиране на \textbf{най-голям / най-малък елемент} - за $O(1)$ време.


\section{Сортиране}
\subsection{Дефиниция}
TODO

\subsection{Елементарни методи за сортиране}
TODO

\subsection{Сортиране - QuickSort}
TODO

\end{document}
