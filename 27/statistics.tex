\documentclass[fleqn,12pt]{article}

\usepackage[margin=20mm]{geometry}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,bulgarian]{babel}
\usepackage[document]{ragged2e}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage[unicode]{hyperref}

\hypersetup{
    colorlinks,
    linktoc=all,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\newtheorem*{Th}{Теорема}
\newtheorem*{Lem}{Лема}
\newtheorem*{Def}{Дефиниция}
\newtheorem*{Claim}{Твърдение}
\newtheorem*{Corollary}{Следствие}

\renewcommand\qedsymbol{$\blacksquare$}

\title{Тема 27\\ Статистика}
\author{ivan ch}
\date{May 28 2021}

\begin{document}

\maketitle

\tableofcontents

\begin{justify}

\section{Случаен експеримент}
\subsection{Дефиниция на случаен експеримент. Основно пространство. Елементарна теория на вероятностите}
В ядрото на статистиката се намира теорията на вероятностите. Да започнем с това, какво наричаме случаен експеримент. 

\textbf{Случаен експеримент} наричаме експеримент, при който условията не определят еднозначно резултата.

\textbf{Основно пространство} наричаме множеството от всички възможни изходи на СЕ. Бележи се с $\Omega$. То има поне 2
елемента. 

Според броя на елементите на $\Omega$ Теорията на вероятностите се дели на 2.
\begin{itemize}
    \item елементарна ТВ : когато $\Omega$ е крайно или изброимо безкрайно множество.
    \item съвременна ТВ : когато $\Omega$ е неизброимо безкрайно множество.
\end{itemize}

\subsection{Събития}
В елементарната ТВ дефинираме \underline{събитие} като част (подмножество) от изходите на СЕ. Означават се напр.
$A, B, C \subseteq \Omega$.

Дефинираме $k_A$ като брой изходи, при които настъпва събитието A. (т.е. |A|). Имаме, че $k_\Omega < \infty$, от 
което следва, че $0 \leq k_A \leq k_\Omega$.

Ако за дадено събитие А имаме, че 
\begin{itemize}
    \item $k_a = 0$, то събитието се нарича невъзможно
    \item $k_a = 1$, то събитието се нарича елементарно
    \item $k_a = k_\Omega$, то събитието се нарича сигурно, т.е. $A = \Omega$
\end{itemize}

Върху събитията може да извършваме операциите обединение, сечение и допълнение.

\section{Вероятност}
\subsection{Класическа вероятност}
Тя е приложима при СЕ с краен брой, равновероятни изходи
\begin{gather*}
    k_\Omega < \infty; \indent P(\omega) = \frac{1}{k_\Omega} = const, \omega \in \Omega
\end{gather*}
\subsection{Общо определение на вероятност при елементарната ТВ}
\textbf{Вероятност} наричаме всяка числова функция дефинирана върху събитията от $\Omega$. Имаме
\[P : \begin{cases}
    \Omega \rightarrow [0, 1]\\
    \omega \rightarrow P(\omega)
\end{cases}
\]
, където $\omega$ е елементарно събитие, а $P(\omega)$ е неговата класическа вероятност.

\noindentЗа дадено събитие A имаме : $P(A) = \sum_{w \in A} P(\omega)$
    
\subsection{Свойства(неотрицателност и нормираност, монотонност и адитивност)}
Така дефинирана, вероятността удовлетворява следните свойства : 
\begin{itemize}
    \item неотрицателност : за произволно събитие $A \subseteq \Omega, P(A) \geq 0$
    \item нормираност : $P(\Omega) = 1$
    \item монотонност : за произволни събития $A,B \subseteq \Omega$, ако $A \subseteq B$, то $P(A) \leq P(B)$
    \item адитивност : за произволни събития $A,B \subseteq \Omega, A \cap B = \emptyset$, то $P(A \cup B) = P(A) + P(B)$
\end{itemize}

\section{Дискретни случайни величини}
\subsection{Случайна величина}
Случайна величина наричаме величина, чиято стойност зависи от резултата на СЕ. Обща дефиниция
\[\xi : \begin{cases}
    \Omega \rightarrow \mathbb{R}\\
    \omega \rightarrow \xi(\omega)
\end{cases} \], т.е. $\xi(\omega)$ е реално число
\subsection{Видове случайни величини}
Случайните величини биват 2 вида:
\begin{itemize}
    \item дискретни: когато $\Omega$ е крайно или изброимо безкрайно множество
    \item непрекъснати: когато $\Omega$ е неизброимо безкрайно множество
\end{itemize}
\subsection{Закон за разпределение(може и таблица на разпределение)}
Представлява съответствие между стойностите на сл. величина и вероятностите на тези стойностите

\begin{tabular}{|c|c|c|c|c|}
    \hline
    $\xi$ & $x_1$ & $\dots$ & $x_n$ & $\dots$ \\
    \hline
    $P$ & $p_1$ & $\dots$ & $p_n$ & $\dots$ \\
    \hline
\end{tabular}

където числата $x_1,\dots,x_n$ са възможните стойности на сл. величина, а числата 
$p_i=P(\{\xi = x_i\}), 0 < p_i < 1, i=1,\dots,n,\dots$ са вероятностите, с които $\xi$ приема тези стойнсти. 

Събитията $\{\xi = x_n\}$ образуват пълна група от несъвместими събития, то $\sum_{i = 1}^{cardinality(\xi)} p_i = 1$, където $cardinality$ връща броя на стойностите на $\xi$.

\subsection{Теглова функция}
Алтернативен начин да се зададе разпределението на дискретна случайна величина. Представлява формула, която връща
вероятността случайната величина да приеме дадена стойност. Обикновено няма зададено означение, но ние ще ползваме 
$p_X$ за дадена дискретна случайна величина $X$.

$p_X : \mathbb{R} -> [0, 1]$

$p_X(x_k) = P(\{X=k\}) = p_k$

Отново е в сила свойството $\sum_k p_X(x_k) = 1$

\subsection{Числови характеристики(на дискретните сл. величини) - мат. очакване и дисперсия)}
\textbf{Математическо очакване} на дискретна случайна величина $\xi$ дава грубо оценка за средната стойност на
величината. $E\xi = \sum_i x_i p_i$

\subsubsection{Свойства на математическото очакване}
\begin{itemize}
    \item ако $\xi$ е сл. величина  и $c=const$, число то $E(c\xi) = cE\xi$
    \item ако $\xi = c = const$, то $E\xi = c$
    \item ако $\xi, \eta$ - сл. величини, то $\xi + \eta$ също е сл. величина и $E\left( \xi + \eta \right) = E\xi +
    E\eta$
\end{itemize}

\textbf{Дисперсия} на дискретна случайна величина представлява мярка за разсейване около средната ѝ стойност. Намира се
по формулата $D\xi = E[\left(\xi - E\xi\right)^2] = \sum_i (x_i - E\xi)^2 p_i = E\xi^2 - (E\xi)^2$. Дисперсията винаги е
неотрицателно число.

\subsubsection{Свойства на дисперсията}
\begin{itemize}
    \item ако $\xi$ е сл. величина  и $c=const$, число то $D\left( c\xi \right) = c^2 D\xi$
    \item ако $\xi = c = const$, то $D\xi = 0$
    \item ако $\xi, \eta$ - сл. величини, то  $D(\xi + \eta) = D\xi + D\eta + 2cov(\xi, \eta)$, 

    където $cov(\xi, \eta) = E\left( \xi \eta \right) - E\xi E\eta$ - ковариация на $\xi$ и $\eta$.
\end{itemize}

\begin{Th}
    Ако $\xi$ и $\eta$ са независими, то те са и некорелирани(тяхната ковариация е 0).
\end{Th}
\begin{Corollary}
    Ако $\xi$ и $\eta$ са независими, то тяхната дисперсия е сума от дисперсиите на всяка от случайните величини.

    $D(\xi + \eta) = D\xi + D\eta$
\end{Corollary}

\subsection{Моменти от ред к}
\textbf{Момент от ред к} наричаме $m_k = E(\xi^k) = \sum_i x_i^kp_i$

\subsection{Централни моменти от ред к}
\textbf{Централен момент от ред к} наричаме $\mathring{m_k} = E((\xi - E\xi)^k) $
$= \sum_i (x_i-m_1)^kp_i$

Това, което забелязваме е, че $m_1 = E\xi$ и $\mathring{m_2} = D\xi$.

\subsection{Пораждаща функция на случайна величина(свойства без док-во)}
\textbf{Пораждаща функция} на сл величина $\xi$ дефинираме така :

$\phi_\xi(t) = E(t^\xi), t > 0$ променлива

или още 

$\phi_\xi(t) = \sum_i t^{x_i}p_i$(степенен ред).

Интересното за тази функция е, че ако вземем нейната първа производна в 1-цата получаваме математическото очакване на 
случайната величина. Ако диференцираме още веднъж, втората производна в 1-цата дава възможност да се намери и 
дисперсията.
\begin{itemize}
    \item 
    $\phi_\xi'(t) = \sum_{i} x_it^{x_{i}-1}p_i \implies \phi_\xi'(1) = \sum_{i} x_ip_i = E\xi = m_1$
    
    \item 
    $\phi_\xi''(t) = \sum_{i} x_i(x_{i}-1)t^{x_{i}-2}p_i \implies \phi_\xi''(1)=\sum_{i} x_i^2p_i - \sum_{i} x_ip_i
    = m_2 - m_1  = m_2 - \phi_\xi'(1)$
\end{itemize}

Математическото очакване намираме директно от $\phi_\xi'(1)$, а дисперсията можем да изведем по следния начин:

$DX = EX^2 - (EX)^2$

$= m_2 - (m_1)^2 = m_2 - m_1 + m_1 - (m_1)^2 $

$= \phi_\xi''(1) + \phi_\xi'(1) - (\phi_\xi'(1))^2$

\subsection{Независими случайни величини}
Две случайни величини се наричат \underline{независими}, ако събитията, заключаващи се в това те да приемат кои да е 
две стойности са независими.

Нека $\xi$ е дискретна случайна величина със закон на разпределение.\\
\begin{tabular}{|c|c|c|c|c|}
    \hline
    $\xi$ & $x_1$ & $\dots$ & $x_n$ & $\dots$ \\
    \hline
    $P$ & $p_1$ & $\dots$ & $p_n$ & $\dots$ \\
    \hline
\end{tabular}

Нека $\eta$ е дискретна случайна величина със закон на разпределение.\\
\begin{tabular}{|c|c|c|c|c|}
    \hline
    $\eta$ & $y_1$ & $\dots$ & $y_m$ & $\dots$ \\
    \hline
    $P$ & $q_1$ & $\dots$ & $q_m$ & $\dots$ \\
    \hline
\end{tabular}

Ако $\xi$ и $\eta$ са независими, то $P(\{\xi=x_i,\eta=y_j\}) = P(\{\xi=x_i\}) P(\{\eta=y_j\}) = p_i q_j$

\section{Дискретни разпределения}
\subsection{Равномерно разпределение}
\subsubsection{Дефиниция} 
Дискретна случайна величина е с равномерно разпределение, когато тя приема краен брой стойности с равна вероятност.
Обикновено се дефинира в някакъв интервал от стойности. 

Нека X е дискретна случайни величина с равномерно разпределение в интервала [a,b], където $a,b \in \mathbf{N}$.
 Броят на елементите в този интервал
е $n = b - a + 1$. Тогава бележим $X \sim U(a, b)$.

Законът за разпределение на X е
\begin{tabular}{|c|c|c|c|}
    \hline
    $X$ & $a$ & $\dots$ & $b$ \\
    \hline
    $P$ & $\frac{1}{n}$ & $\dots$ & $\frac{1}{n}$ \\
    \hline
\end{tabular}

\subsubsection{Числови характеристики} 
\begin{itemize}
    \item мат очакване : $EX = \frac{a+b}{2}$
    
    За общия случай пресмятането на математическото очакване може да стане директно.

    $EX = \sum_{i=1}^n x_ip_i \overset{j=i-1+a}{=} \sum_{j=a}^b j \frac{1}{n}$
    $= \frac{1}{n} \sum_{j=a}^b j = \frac{1}{n} \frac{(n)(a+b)}{2} = \frac{a+b}{2}$

    Предпоследото равенство може да се обоснове, че идва от сума на аритметична прогресия на числата $a$ и $b$ с разлика
    1. Също така при смяна индексите не е нужна това отместване, то следва и от таблицата на разпределение.

    \item дисперсия : $DX = \frac{n^2 - 1}{12}$, за пресмятане виж по долу.
\end{itemize}

За съжаление не става лесно пресмятането на дисперсията с пораждаща ф-я. Тя излиза след формула за геометрича прогресия,
но нейната производна не е дефинирана в 1-цата и трябва с Лопитал. 

Единият вариант е изобщо да кажем, че ще смятаме за в случая интервалът да е от 1 до ествествено число $n$. Предполагам
важи още в началото ако искате да дефинирате разпределението така и да го развиете до края. 

След като намерите очакването и дисперсията за тази величина обаче може да се дефинира друга, която е да е генералния
случай и да се сметнат нейните характеристики от свойствата на очакване и дисперсия, които ако искате може и да
дефинирате в развитието на въпроса.

Нека $Y \sim U(1, n)$. Товава $X = Y + a - 1$ и тя има разпределение $X \sim U(a, b)$.

Това е така, защото имаме съпоставката $n = b - a + 1$, като може, ако искаме  да зададем друга делта между стойностите
в интервала $a, a+k$, в нашия случай $k=1$; иначе е $X = kY + a - k$).

\vspace{10pt}
$DY = EY^2 - (EY)^2  = m_2 - (m_1)^2$ \indent (1)

$m_1 = EY = \sum_{i=1}^n x_ip_i \overset{j = i-1+a}{=} \frac{1}{n} \sum_{j=1}^n j$
$ = \frac{1}{n} \frac{n(n+1)}{2} = \frac{n+1}{2}$

Използвахме формулата за сума от n-естествени числа от 1 до n.
\vspace{10pt}

$m_2 = \sum_{i=1}^n x_i^2 p_i = \frac{1}{n} \sum_{j=1}^n j^2 $ 
$ = \frac{1}{n} \frac{n(n+1)(2n+1)}{6} = \frac{(n+1)(2n+1)}{6}$

Използвахме формулата за сума от квадратите на n-естествени числа от 1 до n.

\vspace{10pt}
Сега заместваме в (1) и получаваме 
$DY = \frac{(n+1)(2n+1)}{6} - \frac{(n+1)^2}{4} = \frac{4n^2+6n+2 - 3n^2-6n-3}{12} = \frac{n^2 - 1}{12}$

\vspace{10pt}
Сега намираме очакването и дисперсията на обобщения случай:

$EX = E(Y+a-1) = E(Y) + a - 1 = \frac{n + 1 + 2a - 2}{2} = \frac{(b-a+1) -1 +2a}{2} = \frac{a+b}{2}$

\vspace{10pt}

$DX = D(Y+a-1) = DY = \frac{n^2 - 1}{12}$

За да обосновете  пресмятането на дисперсията може да споменете свойството на дисперсията $D(aX + b) = a^2DX$, 
където $a,b \in \mathbb{R}$ са константи.

\vspace{10pt}
Едно примерно решение за генералния случай $X \sim U(a, b)$, но почти невъзможно за написване на лист, тъй като
стъпката по опростяване на втория момент е може би доста дълга : 

$m_2 = \sum_{i=1}^n x_i^2 p_i = \frac{1}{n} [\sum_{j=1}^b j^2  - \sum_{j=1}^{a-1} j^2 ]$ 

$ = \frac{1}{(b-a+1)} [\frac{b(b+1)(2b+1)}{6} - \frac{(a-1)a(2(a-1)+1)}{6}]$

$\overset{wolfram \dots}{=} \frac{2a^2 + 2ab - a + 2b^2 + b}{6}$

Сега заместваме в (1) и получаваме 

$\frac{2a^2 + 2ab - a + 2b^2 + b}{6} - \frac{(a+b)^2}{4}$

$ = \frac{2(2a^2 + 2ab - a + 2b^2 + b) - 3(a^2 + 2ab + b^2)}{12}$

$ = \frac{b^2 + a^2 -2ab -2a + 2b}{12} \overset{babev}{=} $

$ = \frac{b^2 + a^2 -2ab -2a + 2b + 1 - 1}{12} = \frac{n^2 - 1}{12}$ 
\subsubsection{Използване}
Равномерното разпределение се използва като модел при честни хазартни игри като зарове или карти, за които се
предполагат еднакви вероятности за всеки резултат.

\subsection{Разпределение на Бернули}
\subsubsection{Дефиниция} 
Описва СЕ ''прост опит'' - т.е. прави се 1 опит и той или е успешен, или не. Единственият параметър е 
вероятността за успех $p$.

Нека $\xi$ е дискретна случайна величина с разпределение на Бернули. Записваме $\xi \sim Ber(n)$

Законът за разпределение има следния вид.
\begin{tabular}{|c|c|c|}
    \hline
    $\xi$ & 0 & 1 \\
    \hline
    $P$ & $q := 1 - p$ & $p$ \\
    \hline
\end{tabular}

\subsubsection{Числови характеристики} 
\begin{itemize}
    \item мат очакване : $E\xi = 0q + 1p = p$
    \item дисперсия : $D\xi = E\xi^2 - (E\xi)^2 = p - p^2 = p(1-p)  = pq$
    \item пораждаща функция : $\phi_\xi(t) = E(t^\xi) = t^0q + t^1p = tp + q$(уравнение на права в равнината)
\end{itemize}

\subsubsection{Използване} 
Среща се в задачи, в които резултатът може да се квалифицира в две категории - успех или неуспех. Примери са хвърляне 
на двулицева монета или дали новородено дете е от искан пол. Също така това разпределение стои в основата на биномното и
геометричното.

\subsection{Биномно разпределение}
\subsubsection{Дефиниция}
Нека $\xi_1, \dots, \xi_n$ са $n$ независими еднакво разпределени дискретни случайни величини всяка с разпределение на 
Бернули с вероятност за успех p.

Дефинираме сл. величина $S_n = \sum_{k=1}^n \xi_k$. ($S_n \sim Bi(n,p)$) и тя има биномно разпределение. Параметрите на 
разпределението са n(брой опити) и p(вероятност за успех в 1 опит).

Можем да я представим като схема на Бернули(имаме n-независими "прости опита" всеки с вероятност за успех p), като 
схемата, както и таблицата на разпределение са :

\begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
    $S_n$ & 0 & 1 & $\dots$ & k & $\dots$ & n \\
    \hline
    $P$ & $q^n$ & $n p q^{n-1}$ & $\dots$ & $C_n^k p^k q^{n-k}$ & $\dots$ & $p^n$ \\
    \hline
\end{tabular}

\subsubsection{Числови характеристики}  
\begin{itemize}
    \item мат очакване : $ES_n = E(\sum_{k=1}^n \xi_k) = E\xi_1 + \dots + E\xi_n = n*p$
    \item дисперсия : $DS_n = D(\sum_{k=1}^n \xi_k) = D\xi_1 + \dots + D\xi_n = n*p*q$(т.к. $\xi_k$ са независими)
    \item пораждаща функция : $\phi_{S_n}(t) = E(t^{S_n}) = E(t^{\xi_1} * \dots * t^{\xi_n})$
    
    $=E(t^{\xi_1}) * \dots * E(t^{\xi_n}) = (tp + q)^n$ 
\end{itemize}
    
Последното равенство излиза от теоремата за независимите са и некорелирани в дефиницията за ковариация тя е нула и 
прехвърляме събираемото с произведението от другата страна.

$E(\xi*\eta) = E\xi + E\eta$

Друг въпрос е дали $t^{\xi_i}$ случайна величина, но най-вероятно да.

\subsubsection{Използване} 
Биномното разпределение моделира т.нар. схема на Бернули. Нека изходът от някакъв експеримент може да се класифицира
само в два взаимоизключващи се класа, например успех и неуспех, присъствие и отсъствие, ези и тура. Тогава за всеки опит
имаме дискретна сл. величина с разпределение на Бернули). Ако проведем такива експерименти при еднакви условия, тогава 
броят на изходите, попадащи в класа на успеха ще се задава с биномно разпределение.

Пример е хвърляме двулицева монета 10 пъти и се питаме каква е вероятността да се падне 3 пъти ези. 

Имаме $X \sim Bi(10, \frac{1}{2})$ и $P(X=3) = C_{10}^3 * (\frac{1}{2})^3 * (1 - \frac{1}{2})^{10-3}$

\subsection{Геометрично разпределение}
\subsubsection{Дефиниция} 
Нека $\xi_1, \dots, \xi_n, \dots$ са независими еднакво разпределени дискретни случайни величини всяка с разпределение 
на Бернули с вероятност за успех p.
Нека дефинираме сл. величина $\tau = min(i : \xi_i = 1)$ т.е. мястото на първата единица в редицата. 

Тогава $\tau$ е 
дискретна случайна величина с геометрично разпределение с параметър $p$ - вероятност за успех Бележим $\tau \sim Ge(p)$.

По този начин имаме схема до първи успех. Законът на разпределение на $\tau$ е.

\begin{tabular}{|c|c|c|c|c|c|}
    \hline
    $\tau$ & 1 & 2 & $\dots$ & n & $\dots$ \\
    \hline
    $P$ & $p$ & $pq$ & $\dots$ & $p q^{n-1}$ & $\dots$ \\
    \hline
\end{tabular}

\subsubsection{Числови характеристики} 
\begin{itemize}
    \item мат очакване : $E\tau = 1p + 2pq + 3pq^2 + \dots = 1(1 - q) + 2(1-q)q + 3(1-q)q^2 + \dots $

    $= 1 - q + 2q - 2q^2 + 3q^2 -3q^3 + \dots = 1 + q + q^2 + \dots = \frac{1}{1-q} = \frac{1}{p}$
    \item дисперсия : $D\tau = \frac{1-p}{p^2}$ ще я намерим с помощта на пораждащата функция
    \item пораждаща функция : $\phi_\tau(t) = E(t^\tau) = \sum_{i=1}^\infty t^i p q^{i - 1}$
    $ = tp \sum_{i=0}^\infty (tq)^i = tp \frac{1}{1-qt} = \frac{pt}{1-qt}$
    \item намиране на дисперсията : 
    $D\tau = E\tau^2 - (E\tau)^2 = E\tau^2 - E\tau + E\tau + (E\tau)^2 $

    $= m_2 - m_1 + m_1 - (m_1)^2 = (m_2 - m_1) + m_1 - (m_1)^2 = \phi_\tau''(1) + \phi_\tau'(1) - (\phi_\tau'(1))^2;$
    
    \vspace{10pt}
    $\phi_\tau'(t) = \frac{p}{(1-qt)^2}; \phi_\tau'(1) = \frac{p}{(1-q)^2} = \frac{1}{p} = E\tau$
    
    $\phi_\tau''(t) = \frac{2pq}{(1-qt)^3}; \phi_\tau''(t) = \frac{2pq}{(1-q)^3} = \frac{2q}{p^2} = \frac{2- 2p}{p^2}$
    
    \vspace{10pt}
    $D\tau = \frac{2- 2p}{p^2} + \frac{1}{p} - \frac{1}{p^2} = \frac{2-2p+p-1}{p^2} = \frac{1-p}{p^2}$
\end{itemize}
\subsubsection{Използване} 
Геометричното разпределение е подходящ модел за изследване надеждността на изделия при многократна употреба. Друг
класически пример е стрелба в цел до улучване на целта.

\subsection{Разпределение на Поасон}
\subsubsection{Дефиниция}
Нека имаме схема на Бернули, в която броят на опитите $n \rightarrow \infty$ и вероятността за успех е 
$p \rightarrow 0$. Това е т.нар. схема на Поасон и ако $\pi$ е дискретна случайна величина с разпределение на 
Поасон с параметър $\lambda = n p = const$ бележим $\pi \sim Po(\lambda)$

Законът на разпределение е

\begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    $\pi$ & 0 & 1 & 2 & $\dots$ & n & $\dots$ \\
    \hline
    $P$ & $e^{-\lambda}$ & $\lambda e^{-\lambda}$ & $\frac{\lambda^2 e^{-\lambda}}{2}$ & $\dots$ & $\frac{\lambda^n
    e^{-\lambda}}{n!}$& $\dots$ \\
    \hline
\end{tabular}

\subsubsection{Числови характеристики} 
Тъй като имаме, че $\lambda = n p$ можем при пресмятанията да използваме очакването и дисперсията на биномното 
разпределение. 
\begin{itemize}
    \item мат очакване : $\lim_{n \rightarrow \infty} ES_n = \lim_{n \rightarrow \infty, p \rightarrow 0} np = \lambda$
    \item дисперсия : $\lim_{n \rightarrow \infty} DS_n = \lim_{n \rightarrow \infty, p \rightarrow 0} npq$
     $ = \lambda \lim_{q \rightarrow 1} q = \lambda * 1 = \lambda$
    \item пораждаща функция : $\phi_\pi(t) = e^{\lambda(t-1)}$
\end{itemize}
\subsubsection{Числови характеристики по втори начин}
\begin{itemize}
    \item пораждаща функция : $\phi_\pi(t) = E(t^\pi) = \sum_{k \geq 0} t^{k}p_k$
    $= \sum_{k \geq 0} t^{k} \frac{e^{-\lambda}\lambda^k}{k!} $

    $= e^{-\lambda} \sum_{k \geq 0} \frac{(\lambda t)^k}{k!}$

    $= e^{-\lambda} e^{\lambda t} = e^{\lambda t - \lambda}$
    \item мат очакване : $E(\pi) = \lambda$
    
    $\phi_\pi'(t) = e^{\lambda t - \lambda} \lambda$ 
    
    $E(\pi) = m_1 = \phi_\pi'(1) = e^0 \lambda = \lambda$
    
    \item дисперсия $D(\pi) = \lambda$
    
    $\phi_\pi''(t) = e^{\lambda t - \lambda} \lambda^2$ 
    
    $\phi_\pi''(1) = e^0 \lambda^2$

    $D(\pi) = E(\pi^2) - (E(\pi))^2 = m_2 - (m_1)^2 = m_2 - m_1 + m_1 - (m_1)^2 = (m_2 - m_1) + m_1 - (m_1)^2$

    $= \phi_\pi''(1) + \phi_\pi'(1) - (\phi_\pi'(1))^2 = \lambda^2 + \lambda - \lambda^2 = \lambda$
\end{itemize}

\subsubsection{Използване} 
Разпределението на Поасон e приближение на биномното разпределение за голям брой опити и ниска вероятност за успех.

Разпределението на Пoaсон се използва за предсказване на дадено събитие А, когато е известно
\begin{itemize}
    \item средният брой на настъпванията на А за всеки единичен константен времеви интервал (ламбдата)
    \item всяко настъпване на А е независимо от предходните, т.е. предисторията на процеса не влияе на текущото му 
    състояние
\end{itemize}

Това е приложимо за природни катаклизми, икономически прогнози или процент неизправности.

\vspace{10pt}

Пример : при 300 разговора месечно в мрежата на Виваком каква е вероятността да настъпят 3 грешки(т.е. 1\% грешки)?

събитие А = {грешка при свързване}, 

дискретна случайна величина X, която брои грешките при свързване при провеждане на 300 разговора.

Ако решаваме със схема на Бернули с n = 300, p = 0,01 , k = 3 (брой настъпвания на събитието)

$P(X = 3) = C_{300}^3 (0,01) ^ 3 (0,99)^{297}$ , което е доста тежка сметка

При решаване със схема на Поасон с параметър $\lambda = np = 3$ имаме

$P(X = 3) = \frac{3^3 e^{-3}}{3!}$, като при пресмятането може да ползваме таблици за апроксимиране на e.
\end{justify}
\end{document}
