\documentclass[fleqn,12pt]{article}

\usepackage[margin=20mm]{geometry}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,bulgarian]{babel}
\usepackage[document]{ragged2e}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{accents}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    linktoc=all,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\newtheorem*{Th}{Теорема}
\newtheorem*{Lem}{Лема}
\newtheorem*{Def}{Дефиниция}
\newtheorem*{Claim}{Твърдение}
\newtheorem*{Corollary}{Следствие}

\renewcommand\qedsymbol{$\blacksquare$}

\title{finals-theme-27-statistics}
\author{ivan ch}
\date{May 28 2021}

\begin{document}

\maketitle

\tableofcontents

\begin{justify}

\section{Случаен експеримент}
\subsection{Дефиниция на случаен експеримент. Основно пространство. Елементарна теория на вероятностите}
В ядрото на статистиката се намира теорията на вероятностите. Да започнем с това, какво наричаме случаен експеримент. 

\textbf{Случаен експеримент} наричаме експеримент, при който условията не определят еднозначно резултата.

\textbf{Основно пространство} наричаме множеството от всички възможни изходи на СЕ. Бележи се с $\Omega$. То има поне 2
елемента. 

Според броя на елементите на $\Omega$ Теорията на вероятностите се дели на 2.
\begin{itemize}
    \item елементарна ТВ : когато $\Omega$ е крайно или изброимо безкрайно множество.
    \item съвременна ТВ : когато $\Omega$ е неизброимо безкрайно множество.
\end{itemize}

\subsection{Събития}
В елементарната ТВ дефинираме \underline{събитие} като част(подмножества) от изходите на СЕ. Означават се напр
$A, B, C \subseteq \Omega$.

Дефинираме $k_A$ като брой изходи, при които настъпва събието A. (т.е. |A|). Имаме, че $k_\Omega < \infty$, от 
което следва, че $0 \leq k_A \leq k_\Omega$.

Ако за дадено събитие А имаме, че 
\begin{itemize}
    \item $k_a = 0$, то събитието се нарича невъзможно
    \item $k_a = 1$, то събитието се нарича елементарно
    \item $k_a = k_\Omega$, то събитието се нарича сигурно, т.е. $A = \Omega$
\end{itemize}

Върху събитията може да извършваме оперициите обединение, сечение и допълнение.

\section{Вероятност}
\subsection{Класическа вероятност}
Тя е приложима при СЕ с краен брой, равновероятни изходи
\begin{gather*}
    k_\Omega < \infty; \indent P(\omega) = \frac{1}{k_\Omega} = const, \omega \in \Omega
\end{gather*}
\subsection{Общо определение на вероятност при елементарната ТВ}
\textbf{Вероятност} наричаме всяка числова функция дефинирана върху събитията от $\Omega$. Имаме
\[P : \begin{cases}
    \Omega \rightarrow (0, 1)\\
    \omega \rightarrow P(\omega)
\end{cases}
\]
, където $\omega$ е елементарно събитие, а $P(\omega)$ е неговата класическа вероятност

\noindentЗа дадено събитие A имаме : $P(A) = \sum_{w \in A}$
    
\subsection{Свойства(неотрицателност и нормираност, монотонност и адитивност)}
Така дефинирана, вероятността удовлетворява следните свойства : 
\begin{itemize}
    \item неотрицателност : за събитие $A \in \Omega, P(A) \geq 0$
    \item нормираност : $P(\Omega) = 1$
    \item монотонност : за събития $A,B \in \Omega, A \subseteq B$, то $P(A) \leq P(B)$
    \item адитивност : за събития $A,B \in \Omega, A \cap B = \emptyset$, то $P(A \cup B) = P(A) + P(B)$
\end{itemize}

\section{Дискретни случайни величини}
\subsection{Случайна величина}
Случайна величина наричаме величина, чиято стойност зависи от резултата на СЕ. Обща дефиниция
\[\xi : \begin{cases}
    \Omega \rightarrow \mathbb{R}\\
    \omega \rightarrow \xi(\omega)
\end{cases} \], т.е. $\xi(\omega)$ е реално число
\subsection{Видове случайни величини}
Случайните величини биват 2 вида:
\begin{itemize}
    \item дискретни : когато $\Omega$ екрайно или изброимо безкрайно множество
    \item непрекъснати : когато $\Omega$ е неизброимо безкрайно множество
\end{itemize}
\subsection{Закон за разпределение}
Представлява съответствие между стойностите на сл. величина и вероятностите на тези стойностите

\begin{tabular}{|c|c|c|c|c|}
    \hline
    $\xi$ & $x_1$ & $\dots$ & $x_n$ & $\dots$ \\
    \hline
    $P$ & $p_1$ & $\dots$ & $p_n$ & $\dots$ \\
    \hline
\end{tabular}

където числата $x_1,\dots,x_n$ са възможните стойности на сл. величина, а числата 
$p_i=P(\{\xi = x_i\}), 0 < p_i < 1, i=1,\dots,n,\dots$ са вероятностите, с които $\xi$ приема тези стойнсти. 

Събитията $\{\xi = x_n\}$ образуват пълна група от несъвместими събития, то $\sum_{i \in values(\xi)} p_i = 1$.

\subsection{Числови характеристики(на дискретните сл. величини) - мат очакване и дисперсия(?техни свойства)}
\textbf{Математическо очакване} на сл величина $\xi$ дава грубо оценка за средната стойност на величината.
$E\xi = \sum_i x_i p_i$

\subsubsection{Свойства на математическото очакване}
\begin{itemize}
    \item ако $\xi$ е сл. величина  и $c=const$, число то $E(c\xi) = cE\xi$
    \item ако $\xi = c = const$, то $E\xi = c$
    \item ако $\xi, \eta$ - сл. величини, то $\xi + \eta$ също е сл. величина и $E\left( \xi + \eta \right) = E\xi +
    E\eta$
\end{itemize}

\textbf{Дисперсия} на сл величина представлява мярка за разсейване около средната ѝ стойност. Намира се по формулата
$D\xi = E[\left(\xi - E\xi\right)^2] = \sum_i (x_i - E\xi)^2 p_i = E\xi^2 - (E\xi)^2$.
Дисперсията винаги е положително число.

\subsubsection{Свойства на дисперсията}
\begin{itemize}
    \item ако $\xi$ е сл. величина  и $c=const$, число то $D\left( c\xi \right) = c^2 D\xi$
    \item ако $\xi = c = const$, то $D\xi = 0$
    \item ако $\xi, \eta$ - сл. величини, то  $D(\xi + \eta) = D\xi + D\eta + 2cov(\xi, \eta)$, 

    където $cov(\xi, \eta) = E\left( \xi*\eta \right) - E\xi * E\eta$ - ковариация на $\xi$ и $\eta$.
\end{itemize}

\begin{Th}
    Ако $\xi$ и $\eta$ са независими, то те са и некорелирани(тяхната ковариация е 0).
\end{Th}
\begin{Corollary}
    Ако $\xi$ и $\eta$ са независими, то тяхната дисперсия е сума от дисперсиите на всяка от случайните величини.

    $D(\xi + \eta) = D\xi + D\eta$
\end{Corollary}

\subsection{Моменти от ред к}
\textbf{Момент от ред к} наричаме $m_k = E(\xi^k) = \sum_i x_i^kp_i$

\subsection{Централни моменти от ред к}
\textbf{Централен момент от ред к} наричаме $\mathring{m_k} = E((\xi - E\xi)^k) $
$= \sum_i (x_i-m_1)^kp_i$

Това, което забелязваме е, че $m_1 = E\xi$ и $\mathring{m_2} = D\xi$.

\subsection{Пораждаща функция на случайна величина(свойства без док-во)}
\textbf{Пораждаща функция} на сл величина $\xi$ дефинираме така :

$\phi_\xi(t) = E(t^\xi), t > 0$ променлива

или още 

$\phi_\xi(t) = \sum_i t^{x_i}p_i$(степенен ред).

Интересното за тази функция е, че ако вземем нейната първа производна в 1-цата получаваме математическото очакване на 
случайната величина. Ако диференцираме още веднъж, втората производна в 1-цата дава възможност да се намери и 
дисперсията.
\begin{itemize}
    \item $\phi_\xi'(t) = \sum_{i} x_it^{x_{i-1}}p_k$\\
    $\implies  \phi_\xi'(1) = \sum_{i} x_ip_i = E\xi = m_1$
    \item $\phi_\xi'(t) = \sum_{i} x_i(x_{i-1})t^{x_{i-2}}p_i$\\
    $\implies \phi_\xi''(1)=\sum_{i} x_i^2p_i - \sum_{i} x_ip_i$
    $= m_2 - m_1  = m_2 - \phi_\xi'(1)$
\end{itemize}

\subsection{Независими случайни величини}
Две случайни величини се наричат \underline{независими}, ако събитията, заключаващи се в това те да приемат кои да е 
две стойности са независими.

Нека $\xi$ е дискретна случайна величина със закон на разпределение.\\
\begin{tabular}{|c|c|c|c|c|}
    \hline
    $\xi$ & $x_1$ & $\dots$ & $x_n$ & $\dots$ \\
    \hline
    $P$ & $p_1$ & $\dots$ & $p_n$ & $\dots$ \\
    \hline
\end{tabular}

Нека $\eta$ е дискретна случайна величина със закон на разпределение.\\
\begin{tabular}{|c|c|c|c|c|}
    \hline
    $\eta$ & $y_1$ & $\dots$ & $y_m$ & $\dots$ \\
    \hline
    $P$ & $q_1$ & $\dots$ & $q_m$ & $\dots$ \\
    \hline
\end{tabular}

Ако $\xi$ и $\eta$ са независими, то $P(\{\xi=x_i,\eta=y_j\}) = P(\{\xi=x_i\})*P(\{\eta=y_j\}) = p_i*q_j$

\section{Дискретни разпределения}
\subsection{Равномерно разпределение}
\subsubsection{Дефиниция} 
Дискретна случайна величина е с равномерно разпределение, когато тя приема краен брой стойности с равна вероятност.
Обикновено се дефинира в някакъв интервал от стойности. 

Нека X е дискретна случайни величина с равномерно разпределение в интервала [a,b], където $a,b \in \mathbf{N}$.
 Броят на елементите в този интервал
е $n = b - a + 1$. Тогава бележим $X \sim U(a, b)$.

Законът за разпределение на X е
\begin{tabular}{|c|c|c|c|}
    \hline
    $X$ & $a$ & $\dots$ & $b$ \\
    \hline
    $P$ & $\frac{1}{n}$ & $\dots$ & $\frac{1}{n}$ \\
    \hline
\end{tabular}

\subsubsection{Числови характеристики} 
\begin{itemize}
    \item мат очакване : $EX = \sum_{i=1}^n x_ip_i \overset{j=i-1+a}{=} \sum_{j=a}^b j \frac{1}{n}$
    $= \frac{1}{n} \sum_{j=a}^b j-1+a = \frac{1}{n} \frac{(n)(a+b)}{2} = \frac{a+b}{2}$
    \item дисперсия : $DX = \frac{n^2 - 1}{12}$, ще я пресметнем чрез моментите
\end{itemize}

$DX = EX^2 - (EX)^2  = m_2 - (m_1)^2$ \indent (1)

В случая нека смятаме с a = 1 и b = n за по-лесни сметки

$m_1 = EX = \sum_{i=1}^n x_ip_i \overset{j = i-1+a}{=} \frac{1}{n} \sum_{j=1}^n j$
$ = \frac{1}{n} \frac{n(n+1)}{2} = \frac{n+1}{2} $(алтернативно)

$m_2 = \sum_{i=1}^n x_i^2 p_i = \frac{1}{n} \sum_{j=1}^n j^2 $ 
$ = \frac{1}{n} \frac{n(n+1)(2n+1)}{6} = \frac{(n+1)(2n+1)}{6}$

Сега заместваме в (1) и получаваме 
$DX = \frac{(n+1)(2n+1)}{6} - \frac{(n+1)^2}{4} = \frac{4n^2+6n+2 - 3n^2-6n-3}{12} = \frac{n^2 - 1}{12}$

Реалното решение : 

$m_2 = \sum_{i=1}^n x_i^2 p_i = \frac{1}{n} [\sum_{j=1}^b j^2  - \sum_{j=1}^{a-1} j^2 ]$ 

$ = \frac{1}{(b-a+1)} [\frac{b(b+1)(2b+1)}{6} - \frac{(a-1)a(2(a-1)+1)}{6}]$

$\overset{wolfram \dots}{=} \frac{2a^2 + 2ab - a + 2b^2 + b}{6}$

Сега заместваме в (1) и получаваме 

$\frac{2a^2 + 2ab - a + 2b^2 + b}{6} - \frac{(a+b)^2}{4}$

$ = \frac{2(2a^2 + 2ab - a + 2b^2 + b) - 3(a^2 + 2ab + b^2)}{12}$

$ = \frac{b^2 + a^2 -2ab -2a + 2b}{12} \overset{babev}{=} $

$ = \frac{b^2 + a^2 -2ab -2a + 2b + 1 - 1}{12} = \frac{n^2 - 1}{12}$ 
\subsubsection{Използване}
Равномерното разпределение се използва като модел при честни хазартни игри като зарове или карти за които се предполагат
еднакви вероятности за всеки резултат.

\subsection{Разпределение на Бернули}
\subsubsection{Дефиниция} 
Описва СЕ "прост опит" - т.е. прави се 1 опит и той или е успешен, или не. Единственият параметър е 
вероятността за успех $p$.

Нека $\xi$ е дискретна случайна величина с разпределение на Бернули. Записваме $\xi \sim Ber(n)$

Законът за разпределение има следния вид.
\begin{tabular}{|c|c|c|}
    \hline
    $\xi$ & 0 & 1 \\
    \hline
    $P$ & $q := 1 - p$ & $p$ \\
    \hline
\end{tabular}

\subsubsection{Числови характеристики} 
\begin{itemize}
    \item мат очакване : $E\xi = 0q + 1p = p$
    \item дисперсия : $D\xi = E\xi - (E\xi)^2 = p - p^2 = p(1-p)  = pq$
    \item пораждаща функция : $\phi_\xi(t) = E(t^\xi) = t^0q + t^1p = tp + q$(уравнение на права в равнината)
\end{itemize}

\subsubsection{Използване} 
Среща се в задачи, в които резултатът може да се квалифицира в две категории - успех или неуспех. Примери са хвърляне 
на двулицева монета.

\subsection{Биномно разпределение}
Нека $\xi_1, \dots, \xi_n$ са $n$ независими еднакво разпределени дискретни случайни величини всяка с разпределение на 
Бернули с вероятност за успех p.

Дефинираме сл. величина $S_n = \sum_{k=1}^n \xi_k$. ($S_n \sim Bi(n,p)$) и тя има биномно разпределение с параметри n(брой
опити) и p(вероятност за успех в 1 опит).

Можем да я представим като схема на Бернули(имаме n-независими "прости опита" всеки с вероятност за успех p).

\begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
    $S_n$ & 0 & 1 & $\dots$ & k & $\dots$ & n \\
    \hline
    $P$ & $q^n$ & $n*p*q^{n-1}$ & $\dots$ & $C_n^k * p^k * q^{n-k}$ & $\dots$ & $p^n$ \\
    \hline
\end{tabular}

\subsubsection{Числови характеристики}  
\begin{itemize}
    \item мат очакване : $ES_n = E(\sum_{k=1}^n \xi_k) = E\xi_1 + \dots + E\xi_n = n*p$
    \item дисперсия : $DS_n = D(\sum_{k=1}^n \xi_k) = D\xi_1 + \dots + D\xi_n = n*p*q$(т.к. $\xi_k$ са независими)
    \item пораждаща функция : $\phi_{S_n}(t) = E(t^{S_n}) = E(t^{\xi_1} * \dots * t^{\xi_n})$ \\
    (от Т за независимите са некорелирани в дефиницията за ковариация излиза $E(\xi*\eta) = E\xi + E\eta)$ \\
    ($t^{\xi_i}$ случайна величина ли е?) \\
    $=E(t^{\xi_1}) * \dots * E(t^{\xi_n}) = (tp + q)^n$ 
\end{itemize}

\subsubsection{Използване} 
Биномното разпределение моделира т.нар. схема на Бернули. Нека изходът от някакъв експеримент може да се класифицира
само в два взаимоизключващи се класа – например успех и неуспех, присъствие и отсъствие, ези и тура и т.н(т.е. дискретна
сл. величина с разпределение на Бернули). Ако проведем такива експерименти при еднакви условия, тогава броят на
изходите, попадащи в един от двата класа, примерно брой успехи с вероятност, ще се задава с биномно разпределение.

\subsection{Геометрично разпределение}
\subsubsection{Дефиниция} 
Нека $\xi_1, \dots, \xi_n, \dots$ са независими еднакво разпределени дискретни случайни величини всяка с разпределение 
на Бернули с вероятност за успех p.
Нека дефинираме сл. величина $\tau = min(i : \xi_i = 1)$ т.е. мястото на първата единица в редицата. 

Тогава $\tau$ е 
дискретна случайна величина с геометрично разпределение с параметър $p$ - вероятност за успех Бележим $\tau \sim Ge(p)$.

По този начин имаме схема до първи успех. Законът на разпределение на $\tau$ е.

\begin{tabular}{|c|c|c|c|c|c|}
    \hline
    $\tau$ & 1 & 2 & $\dots$ & n & $\dots$ \\
    \hline
    $P$ & $p$ & $pq$ & $\dots$ & $p * q^{n-1}$ & $\dots$ \\
    \hline
\end{tabular}

\subsubsection{Числови характеристики} 
\begin{itemize}
    \item мат очакване : $E\tau = 1p + 2pq + 3pq^2 + \dots = 1(1 - q) + 2(1-q)q + 3(1-q)q^2 + \dots = 
    1 - q + 2q - 2q^2 + 3q^2 -3q^3 + \dots = 1 + q + q^2 + \dots = \frac{1}{1-q} = \frac{1}{p}$
    \item дисперсия : $D\tau = \frac{1-p}{p^2}$ ще я намерим с помощта на пораждащата функция
    \item пораждаща функция : $\phi_\tau(t) = E(t^\tau) = \sum_{i=1}^\infty t^i p q^{i - 1}$
    $ = tp \sum_{i=0}^\infty (tq)^i = tp*\frac{1}{1-qt} = \frac{pt}{1-qt}$
    \item намиране на дисперсията : 
    $D\tau = E\tau^2 - (E\tau)^2 = E\tau^2 - E\tau + E\tau + (E\tau)^2 = m_2 - m_1 + m_1 - (m_1)^2$
    $= \phi_\tau''(t) + \phi_\tau'(t) - (\phi_\tau(t))^2;$
    
    $\phi_\tau'(t) = \frac{p}{(1-qt)^2}; \phi_\tau'(1) = \frac{p}{(1-q)^2} = \frac{1}{p} = E\tau$
    
    $\phi_\tau''(t) = \frac{2pq}{(1-qt)^3}; \phi_\tau''(t) = \frac{2pq}{1-q}^3 = \frac{2q}{p^2} = \frac{2- 2p}{p^2}$
    
    $D\tau = \frac{2- 2p}{p^2} + \frac{1}{p} - \frac{1}{p^2} = \frac{2-2p+p-1}{p^2} = \frac{1-p}{p^2}$
\end{itemize}
\subsubsection{Използване} 
Геометричното разпределение е подходящ модел за изследване на надеждност на изделия при многократна употреба. Друг
класически пример е стрелба в цел до улучване на целта.

\subsection{Разпределение на Поансон}
\subsubsection{Дефиниция}
Нека имаме схема на Бернули, в която броят на опитите $n \rightarrow \infty$ и вероятността за успех е 
$p \rightarrow 0$. Това е т.нар. схема на Поансон и ако $\pi$ е дискретна случайна величина с разпределение на 
Поансон с параметър $\lambda = n*p = const$ бележим $\pi \sim Po(\lambda)$

Законът на разпределение е

\begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    $\pi$ & 0 & 1 & 2 & $\dots$ & n & $\dots$ \\
    \hline
    $P$ & $e^-\lambda$ & $\lambda e^{-\lambda}$ & $\frac{\lambda^2 e^{-\lambda}}{2}$ & $\dots$ & $\frac{\lambda^n
    e^{-\lambda}}{n!}$& $\dots$ \\
    \hline
\end{tabular}

\subsubsection{Числови характеристики} 
Тъй като имаме, че $\lambda = n*p$ можем при пресмятанията да използваме очакването и дисперсията на биномното 
разпределение. 
\begin{itemize}
    \item мат очакване : $\lim_{n \rightarrow \infty} ES_n = \lim_{n \rightarrow \infty, p \rightarrow 0} np = \lambda$
    \item дисперсия : $\lim_{n \rightarrow \infty} DS_n = \lim_{n \rightarrow \infty, p \rightarrow 0} npq = \lambda
    \lim q = \lambda * 1 = \lambda$
    \item пораждаща функция : $\phi_\pi(t) = e^{\lambda(t-1)}$
\end{itemize}
\subsubsection{Използване} 
Разпределението на Поасон e приближение на биномното разпределение за голям брой опити и ниска вероятност за успех.

Разпределението на Паонсон се използва за предсказване на дадено събитие А, когато е известно
\begin{itemize}
    \item средният брой на настъпванията на А за всеки единичен константен времеви интервал (ламбдата)
    \item всяко настъпване на А е независимо от предходните, т.е. предисторията на процеса не влияе на текущото му 
    състояние
\end{itemize}

Това е приложимо за природни катаклизми, икономически прогнози или процент неизправности.

Пример : при 300 разговора месечно в мрежата на Виваком каква е вероятността да настъпят 3 грешки(т.е. 1\%)?

събитие А = {грешка при свързване}, 

Ако решаваме със схема на Бернули с n = 300, p = 0,01 , k = 3(брой на настъпване на събитието)

$P(A_3) = C_{300}^3 * (0,01) ^ 3 * (0,99)^{297}$ , което е доста тежка сметка

При решаване със схема на Поансон с параметър $\lambda = np = 3$ и 

$P(A_3) = \frac{3^3 * e^{-3}}{3!}$, като при присмятането може да ползваме таблици за апроксимиране на e
\end{justify}
\end{document}